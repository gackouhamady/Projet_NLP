{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import treetaggerwrapper\n",
    "import seaborn as sns\n",
    "# Ignorer les warnings spécifiques\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'petroff10', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)\n",
    "plt.style.use('default')\n",
    "sns.set_theme()  # Sets Seaborn's default themes for Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traitement de Datasets/input_files/NNC_test_text.txt avec le tagset penn.par...\n",
      "Treetagger a traité avec succès Datasets/input_files/NNC_test_text.txt\n",
      "Précision pour Datasets/input_files/NNC_test_text.txt : 0.0000\n",
      "\n",
      "Traitement de Datasets/input_files/that_adv.txt avec le tagset penn.par...\n",
      "Treetagger a traité avec succès Datasets/input_files/that_adv.txt\n",
      "Précision pour Datasets/input_files/that_adv.txt : 0.0000\n",
      "\n",
      "Traitement de Datasets/input_files/that_conjunction.txt avec le tagset penn.par...\n",
      "Treetagger a traité avec succès Datasets/input_files/that_conjunction.txt\n",
      "Précision pour Datasets/input_files/that_conjunction.txt : 0.0000\n",
      "\n",
      "Traitement de Datasets/input_files/that_determiner.txt avec le tagset penn.par...\n",
      "Treetagger a traité avec succès Datasets/input_files/that_determiner.txt\n",
      "Précision pour Datasets/input_files/that_determiner.txt : 0.0000\n",
      "\n",
      "Traitement de Datasets/input_files/that_pronoun.txt avec le tagset penn.par...\n",
      "Treetagger a traité avec succès Datasets/input_files/that_pronoun.txt\n",
      "Précision pour Datasets/input_files/that_pronoun.txt : 0.0000\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_treetagger(input_file, output_file, TAGPARFILE='penn.par'):\n",
    "    \"\"\"\n",
    "    Exécute Treetagger sur le fichier d'entrée et sauvegarde les résultats dans le fichier de sortie.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = [\"tree-tagger\", TAGPARFILE, input_file, output_file]\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Treetagger a traité avec succès {input_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Erreur lors de l'exécution de Treetagger : {e}\")\n",
    "\n",
    "def evaluate_precision(tagged_file, reference_file):\n",
    "    \"\"\"\n",
    "    Compare les étiquettes du fichier traité par Treetagger avec le fichier de référence\n",
    "    pour calculer la précision.\n",
    "    \"\"\"\n",
    "    total_tags = 0\n",
    "    correct_tags = 0\n",
    "\n",
    "    with open(tagged_file, 'r') as tf, open(reference_file, 'r') as rf:\n",
    "        for tagged_line, reference_line in zip(tf, rf):\n",
    "            tagged_tokens = tagged_line.strip().split()\n",
    "            reference_tokens = reference_line.strip().split()\n",
    "            \n",
    "            for tagged_token, reference_token in zip(tagged_tokens, reference_tokens):\n",
    "                if '/' in tagged_token and '/' in reference_token:\n",
    "                    tagged_word, tagged_tag = tagged_token.rsplit('/', 1)\n",
    "                    reference_word, reference_tag = reference_token.rsplit('/', 1)\n",
    "                    \n",
    "                    if tagged_tag == reference_tag:\n",
    "                        correct_tags += 1\n",
    "                    total_tags += 1\n",
    "\n",
    "    precision = correct_tags / total_tags if total_tags > 0 else 0\n",
    "    return precision\n",
    "\n",
    "def run_tests_on_files(input_files, output_files, tagset='penn.par', reference_files=None):\n",
    "    \"\"\"\n",
    "    Exécute Treetagger sur tous les fichiers d'entrée et évalue la précision pour chaque fichier de test.\n",
    "    \"\"\"\n",
    "    for input_file, output_file, reference_file in zip(input_files, output_files, reference_files):\n",
    "        print(f\"\\nTraitement de {input_file} avec le tagset {tagset}...\")\n",
    "        # Exécution de Treetagger\n",
    "        run_treetagger(input_file, output_file, tagset)\n",
    "        # Calcul de la précision\n",
    "        precision = evaluate_precision(output_file, reference_file)\n",
    "        print(f\"Précision pour {input_file} : {precision:.4f}\")\n",
    "\n",
    "# Liste des fichiers de test pour les différents tagsets\n",
    "input_files = [\n",
    "    \"Datasets/input_files/NNC_test_text.txt\", \n",
    "    \"Datasets/input_files/that_adv.txt\",\n",
    "    \"Datasets/input_files/that_conjunction.txt\", \n",
    "    \"Datasets/input_files/that_determiner.txt\",\n",
    "    \"Datasets/input_files/that_pronoun.txt\"\n",
    "]\n",
    "output_files = [\n",
    "    \"Datasets/output_files/test_NNC_output.txt\", \n",
    "    \"Datasets/output_files/test_that_adv_output.txt\", \n",
    "    \"Datasets/output_files/test_that_conjountion_output.txt\",\n",
    "    \"Datasets/output_files/test_that_determiner_output.txt\",\n",
    "    \"Datasets/output_files/test_that_pronoun_output.txt\"\n",
    "]\n",
    "reference_files = [\n",
    "    \"Datasets/reference_files/that_NNC_reference.text\",\n",
    "    \"Datasets/reference_files/that_adv_reference.txt\", \n",
    "    \"Datasets/reference_files/that_conjountion_reference.txt\", \n",
    "    \"Datasets/reference_files/that_determiner_reference.txt\",\n",
    "    \"Datasets/reference_files/that_pronoun_reference.txt\"\n",
    "]\n",
    "\n",
    "# Exécution des tests\n",
    "run_tests_on_files(input_files, output_files, 'penn.par', reference_files)\n",
    "# run_tests_on_files(input_files, output_files, 'bnc.par', reference_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define helper functions for Treetagger\n",
    "\n",
    "def run_treetagger(input_file, output_file, language=\"english\"):\n",
    "    \"\"\"\n",
    "    Runs Treetagger on the input file and saves the output to output_file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = [\"tree-tagger\", language, input_file, output_file]\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Treetagger successfully processed {input_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Treetagger: {e}\")\n",
    "\n",
    "\n",
    "def parse_treetagger_output(output_file):\n",
    "    \"\"\"\n",
    "    Parses the Treetagger output into a structured DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(output_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                word, tag, lemma = line.strip().split(\"\\t\")\n",
    "                data.append({\"Word\": word, \"Tag\": tag, \"Lemma\": lemma})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Load and preprocess datasets\n",
    "def load_datasets(folder_path):\n",
    "    \"\"\"\n",
    "    Loads datasets for evaluation from the specified folder.\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            dataset_name = file.split(\".\")[0]\n",
    "            datasets[dataset_name] = os.path.join(folder_path, file)\n",
    "    return datasets\n",
    "\n",
    "# Step 3: Evaluate the precision of tags\n",
    "def evaluate_tags(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluates precision for the predicted tags against ground truth.\n",
    "    \"\"\"\n",
    "    y_true = ground_truth[\"Tag\"]\n",
    "    y_pred = predictions[\"Tag\"]\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    return precision, classification_report(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Step 4: Visualization\n",
    "def plot_precision_results(results):\n",
    "    \"\"\"\n",
    "    Plots precision results for different datasets.\n",
    "    \"\"\"\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.plot(kind=\"bar\", x=\"Dataset\", y=\"Precision\", color=\"skyblue\", legend=False)\n",
    "    plt.title(\"Precision Results by Dataset\")\n",
    "    plt.xlabel(\"Dataset\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: Main Workflow\n",
    "def main():\n",
    "    # Paths for input/output\n",
    "    input_folder = \"./datasets/test_files\"  # Replace with your folder path\n",
    "    output_folder = \"./datasets/outputs\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load datasets\n",
    "    datasets = load_datasets(input_folder)\n",
    "\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    for dataset_name, input_file in datasets.items():\n",
    "        print(f\"Processing dataset: {dataset_name}\")\n",
    "\n",
    "        # Run Treetagger\n",
    "        output_file = os.path.join(output_folder, f\"{dataset_name}_output.txt\")\n",
    "        run_treetagger(input_file, output_file)\n",
    "\n",
    "        # Parse Treetagger output\n",
    "        predictions = parse_treetagger_output(output_file)\n",
    "\n",
    "        # Ground truth comparison (simulated, replace with actual ground truth file)\n",
    "        ground_truth_file = os.path.join(input_folder, f\"{dataset_name}_ground_truth.csv\")\n",
    "        ground_truth = pd.read_csv(ground_truth_file)\n",
    "\n",
    "        # Evaluate precision\n",
    "        precision, report = evaluate_tags(predictions, ground_truth)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\"Dataset\": dataset_name, \"Precision\": precision})\n",
    "\n",
    "        # Print classification report\n",
    "        print(f\"Classification Report for {dataset_name}:\\n{report}\")\n",
    "\n",
    "    # Plot results\n",
    "    plot_precision_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
